{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1)\n",
    "Download the ElasticSearch version thats compatible with your system from Lucene here https://www.elastic.co/downloads/elasticsearch\n",
    "\n",
    "I also installed the python bindings for elasticsearch using pip. The python bindings of elasticsearch allows for rapid integration with all the other python packages that I am using in chemistry (RDKIT, sklearn, etc...)\n",
    "\n",
    "Once you have downloaded elasticsearch, make sure the elasticsearch server is up and running (For my windows machine it's on port 9200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2)\n",
    "\n",
    "In this step we define a python object that contains information about the fragmentized molecule. By working with python objects, this can help us in later steps when we perform the bulk loading of data. Just remember you can customize this however you want and add as many properties such as molecular weight, ALogP, etc... as you want. By having more properties, this may help in indexing your molecule of choice by ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "class FragmentData():\n",
    "    \"\"\"\n",
    "        We define a class that contains basic info about the fragmentized molecule, in this case we have the smiles data, list of fragments\n",
    "        the chembl id, the standard inchi, and mol regno\n",
    "    \"\"\"\n",
    "    def __init__(self, chembl_id, smiles, fragments, standard_inchi, mol_regno):\n",
    "        self.id = chembl_id\n",
    "        self.smiles = smiles\n",
    "        self.fragments = fragments\n",
    "        self.standard_inchi = standard_inchi\n",
    "        self.mol_regno = mol_regno\n",
    "\n",
    "    def __str__(self):\n",
    "        return textwrap.dedent(\"\"\"\\\n",
    "            Id: {}          \n",
    "            smiles: {}   \n",
    "            fragments: {}\n",
    "            standard_inchi: {}\n",
    "            mol_regno:{}\n",
    "        \"\"\").format(self.id, self.smiles, self.fragments, self.standard_inchi,\n",
    "                    self.mol_regno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3) \n",
    "\n",
    "In the following step we create the elasticsearch index and document type where we store our fragmentized molecules. You can learn more about the basics of elasticsearch here https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "from typing import List\n",
    "from elasticsearch.helpers import bulk\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME = 'chembl_data'  ### this would be analogous to a database\n",
    "DOC_TYPE = 'mol_frags'   ### this would be analogous to a collection within a database of similar \"documents\"\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'chembl_data'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=INDEX_NAME, ignore=404)   ## delete the INDEX if present\n",
    "### creates the index with dynamic mappings, meaning we dont define the properties of the document fields when we create the index\n",
    "es.indices.create(             \n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            'mappings': {},\n",
    "            'settings': {},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we define some helper functions to help load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(es, input_data):\n",
    "    success, _ = bulk(es, set_data(input_data))\n",
    "    print(success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data(fragment_data):\n",
    "    for frag in fragment_data:\n",
    "        yield {\n",
    "            \"_op_type\": \"create\",\n",
    "            \"_index\": INDEX_NAME,\n",
    "            \"_type\": DOC_TYPE,\n",
    "            \"_id\":frag.id,\n",
    "            \"_source\":{\n",
    "                \"smiles\": frag.smiles,\n",
    "                \"fragments\": frag.fragments,\n",
    "                \"standard_inchi\": frag.standard_inchi,\n",
    "                \"mol_regno\": frag.mol_regno,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_loader(fragment_json):\n",
    "    _all_frags = []\n",
    "    with open(fragment_json) as fragment_file:\n",
    "        for frag in json.load(fragment_file):\n",
    "            json_data = {key.lower():val for key,val in frag.items()}\n",
    "            frag_data = FragmentData(**json_data)\n",
    "            _all_frags.append(frag_data)\n",
    "    return _all_frags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the set_data function is a generator that takes what the fragment_loader function read and uses that to create json documents on the fly, the example below is what it would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_op_type': 'create',\n",
       " '_index': 'chembl_data',\n",
       " '_type': 'mol_frags',\n",
       " '_id': 'CHEMBL1644781',\n",
       " '_source': {'smiles': 'C\\\\C(=C/c1cc(F)c(OCCC(F)F)cc1F)\\\\C(=O)N[C@@H]2[C@H](O)[C@@H](O)[C@H]3OCO[C@H]3[C@@H]2O',\n",
       "  'fragments': ['[Xe]O[Xe]',\n",
       "   '[Xe]c1cc(F)c([Xe])cc1F',\n",
       "   '[Xe]C[Xe]',\n",
       "   '[Xe][C@@H]1[C@H](O)[C@@H](O)[C@H]2OCO[C@H]2[C@@H]1O',\n",
       "   '[Xe]C(=O)C([Xe])C',\n",
       "   '[Xe]N[Xe]',\n",
       "   '[Xe]CCC(F)F'],\n",
       "  'standard_inchi': 'InChI=1S/C20H23F4NO7/c1-8(4-9-5-11(22)12(6-10(9)21)30-3-2-13(23)24)20(29)25-14-15(26)17(28)19-18(16(14)27)31-7-32-19/h4-6,13-19,26-28H,2-3,7H2,1H3,(H,25,29)/b8-4+/t14-,15+,16-,17-,18+,19-/m1/s1',\n",
       "  'mol_regno': 1059788}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(set_data(fragment_loader('CHEMBL_Molecules_fragments_950000_1000000.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we bulk load the saved fragmentized molecules into elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48520\n"
     ]
    }
   ],
   "source": [
    "fragment_json = 'CHEMBL_Molecules_fragments_950000_1000000.json'\n",
    "load(es,fragment_loader(fragment_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! it means 48520 documents (Same number as entries in the file) were loaded into our elasticsearch database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
